import pandas as pd
import sqlite3
import os

# --- Configuration ---
DATABASE_NAME = './datasets/audio_predictions.db'

# Paths to CSV files generated by predict_new_audio.py
# Make sure these paths match where predict_new_audio.py saves its outputs.
NEW_AUDIO_FEATURES_RAW_CSV = './datasets/new_audio_features_raw.csv'
NEW_AUDIO_PREDICTED_VA_CSV = './datasets/new_audio_predicted_va.csv'
NEW_AUDIO_DESCRIPTOR_SCORES_CSV = './datasets/new_audio_descriptor_scores.csv'

def create_tables(conn):
    """Creates the necessary tables in the SQLite database if they don't exist."""
    cursor = conn.cursor()

    # Table for audio files: Stores unique filenames and generates a primary key ID.
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS audio_files (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            filename TEXT UNIQUE NOT NULL
        )
    ''')

    # Table for predicted Valence and Arousal scores: Links to audio_files by file_id.
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS predicted_va_scores (
            file_id INTEGER PRIMARY KEY,
            valence REAL NOT NULL,
            arousal REAL NOT NULL,
            FOREIGN KEY (file_id) REFERENCES audio_files(id)
        )
    ''')

    # Table for audio features: Stores individual features for each file.
    # Normalized structure: one row per feature per file.
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS audio_features (
            file_id INTEGER,
            feature_name TEXT NOT NULL,
            feature_value REAL NOT NULL,
            PRIMARY KEY (file_id, feature_name), -- Composite primary key
            FOREIGN KEY (file_id) REFERENCES audio_files(id)
        )
    ''')

    # Table for descriptor scores: Stores scores for each emotional descriptor.
    # Normalized structure: one row per descriptor per file.
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS descriptor_scores (
            file_id INTEGER,
            descriptor_name TEXT NOT NULL,
            score REAL NOT NULL,
            PRIMARY KEY (file_id, descriptor_name), -- Composite primary key
            FOREIGN KEY (file_id) REFERENCES audio_files(id)
        )
    ''')
    conn.commit()
    print("Database tables created or verified.")

def log_data_to_db(features_df, va_scores_df, descriptor_scores_df, db_name):
    """Logs the provided DataFrame data into the specified SQLite database."""
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        create_tables(conn) # Ensure tables exist
        cursor = conn.cursor()

        # Step 1: Insert filenames into audio_files and get their unique IDs
        file_id_map = {}
        for filename in features_df['file'].unique():
            # INSERT OR IGNORE avoids error if filename already exists
            cursor.execute('INSERT OR IGNORE INTO audio_files (filename) VALUES (?)', (filename,))
            # Retrieve the ID for the filename (whether newly inserted or existing)
            cursor.execute('SELECT id FROM audio_files WHERE filename = ?', (filename,))
            file_id_map[filename] = cursor.fetchone()[0]
        conn.commit()
        print(f"Logged {len(file_id_map)} unique audio files.")

        # Step 2: Insert predicted VA scores
        for index, row in va_scores_df.iterrows():
            filename = row['file']
            file_id = file_id_map.get(filename)
            if file_id is None:
                print(f"Warning: File '{filename}' not found in features data, skipping VA score.")
                continue
            # INSERT OR REPLACE handles updates if data for file_id already exists
            cursor.execute('''
                INSERT OR REPLACE INTO predicted_va_scores (file_id, valence, arousal)
                VALUES (?, ?, ?)
            ''', (file_id, row['valence'], row['arousal']))
        conn.commit()
        print(f"Logged {len(va_scores_df)} predicted VA scores.")

        # Step 3: Insert audio features
        # Identify feature columns by excluding 'file' and any potential 'value' column from original dataset
        feature_cols = [col for col in features_df.columns if col not in ['file', 'value']]
        
        feature_insert_count = 0
        for index, row in features_df.iterrows():
            filename = row['file']
            file_id = file_id_map.get(filename)
            if file_id is None:
                continue # Skip if file_id not found

            for feature_name in feature_cols:
                cursor.execute('''
                    INSERT OR REPLACE INTO audio_features (file_id, feature_name, feature_value)
                    VALUES (?, ?, ?)
                ''', (file_id, feature_name, row[feature_name]))
                feature_insert_count += 1
        conn.commit()
        print(f"Logged {feature_insert_count} audio features.")

        # Step 4: Insert descriptor scores
        # Identify descriptor columns by excluding 'file', 'valence', and 'arousal'
        descriptor_cols = [col for col in descriptor_scores_df.columns if col not in ['file', 'valence', 'arousal']]

        descriptor_insert_count = 0
        for index, row in descriptor_scores_df.iterrows():
            filename = row['file']
            file_id = file_id_map.get(filename)
            if file_id is None:
                continue # Skip if file_id not found

            for descriptor_name in descriptor_cols:
                cursor.execute('''
                    INSERT OR REPLACE INTO descriptor_scores (file_id, descriptor_name, score)
                    VALUES (?, ?, ?)
                ''', (file_id, descriptor_name, row[descriptor_name]))
                descriptor_insert_count += 1
        conn.commit()
        print(f"Logged {descriptor_insert_count} descriptor scores.")

    except sqlite3.Error as e:
        print(f"Database error: {e}")
        if conn:
            conn.rollback() # Rollback all changes if an error occurs
    except FileNotFoundError as e:
        print(f"Error: One or more input CSV files not found. Please ensure they exist: {e}")
    except KeyError as e:
        print(f"Error: Missing expected column in CSV file: {e}. Check CSV structure and column names.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
    finally:
        if conn:
            conn.close()
            print("Database connection closed.")

if __name__ == "__main__":
    print(f"--- Starting logging process to {DATABASE_NAME} ---")

    # Load data from CSVs
    try:
        features_df = pd.read_csv(NEW_AUDIO_FEATURES_RAW_CSV)
        va_scores_df = pd.read_csv(NEW_AUDIO_PREDICTED_VA_CSV)
        descriptor_scores_df = pd.read_csv(NEW_AUDIO_DESCRIPTOR_SCORES_CSV)
        print("Successfully loaded input CSV files.")
    except FileNotFoundError:
        print(f"Error: One or more input CSV files not found.")
        print(f"Please ensure '{NEW_AUDIO_FEATURES_RAW_CSV}', '{NEW_AUDIO_PREDICTED_VA_CSV}', and '{NEW_AUDIO_DESCRIPTOR_SCORES_CSV}'")
        print("exist in the same directory as this script, or provide their full paths.")
        print("\nRemember to modify 'predict_new_audio.py' to save 'new_audio_features_raw.csv' and 'new_audio_predicted_va.csv'.")
        exit()
    except pd.errors.EmptyDataError as e:
        print(f"Error: One of the CSV files is empty: {e}")
        exit()
    except Exception as e:
        print(f"An unexpected error occurred while loading CSVs: {e}")
        exit()
    
    # Basic validation that 'file' column exists for linking
    if 'file' not in features_df.columns:
        print(f"Error: '{NEW_AUDIO_FEATURES_RAW_CSV}' must contain a 'file' column for linking.")
        exit()
    if 'file' not in va_scores_df.columns:
        print(f"Error: '{NEW_AUDIO_PREDICTED_VA_CSV}' must contain a 'file' column for linking.")
        exit()
    if 'file' not in descriptor_scores_df.columns:
        # The descriptor CSV usually has 'file', 'valence', 'arousal' and then descriptors
        # So we just need to ensure 'file' is there.
        print(f"Error: '{NEW_AUDIO_DESCRIPTOR_SCORES_CSV}' must contain a 'file' column for linking.")
        exit()


    log_data_to_db(features_df, va_scores_df, descriptor_scores_df, DATABASE_NAME)
    print("--- Logging process complete ---")